{\n "cells": [\n  {\n   "cell_type": "markdown",\n   "metadata": {},\n   "source": [\n    "# MobileNetV2 Training & Quantization for Edge AI\n",\n    "\n",\n    "This notebook trains an ultra-lightweight MobileNetV2 model for breast cancer detection and applies quantization for MAX78000 deployment.\n",\n    "\n",\n    "## Steps:\n",\n    "1. Load preprocessed data\n",\n    "2. Build MobileNetV2 model (α=0.35)\n",\n    "3. Train with data augmentation\n",\n    "4. Evaluate performance\n",\n    "5. Apply quantization-aware training (QAT)\n",\n    "6. Export quantized model"\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "import numpy as np\n",\n    "import tensorflow as tf\n",\n    "from tensorflow import keras\n",\n    "from tensorflow.keras import layers\n",\n    "from tensorflow.keras.applications import MobileNetV2\n",\n    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",\n    "import matplotlib.pyplot as plt\n",\n    "import seaborn as sns\n",\n    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",\n    "import os\n",\n    "\n",\n    "print(f\"TensorFlow version: {tf.__version__}\")\n",\n    "print(f\"Keras version: {keras.__version__}\")\n",\n    "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))"\n   ]\n  },\n  {\n   "cell_type": "markdown",\n   "metadata": {},\n   "source": [\n    "## Configuration"\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "# Paths\n",\n    "PROCESSED_DATA_DIR = '../data/processed'\n",\n    "MODEL_DIR = '../models'\n",\n    "os.makedirs(MODEL_DIR, exist_ok=True)\n",\n    "\n",\n    "# Model parameters\n",\n    "IMAGE_SIZE = 96\n",\n    "ALPHA = 0.35  # Width multiplier for ultra-lightweight model\n",\n    "INPUT_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3)\n",\n    "\n",\n    "# Training parameters\n",\n    "BATCH_SIZE = 32\n",\n    "EPOCHS = 100\n",\n    "LEARNING_RATE = 0.001\n",\n    "SEED = 42\n",\n    "\n",\n    "# Set seeds\n",\n    "np.random.seed(SEED)\n",\n    "tf.random.set_seed(SEED)\n",\n    "\n",\n    "print(f\"Image Size: {IMAGE_SIZE}x{IMAGE_SIZE}\")\n",\n    "print(f\"Alpha (Width Multiplier): {ALPHA}\")\n",\n    "print(f\"Batch Size: {BATCH_SIZE}\")\n",\n    "print(f\"Epochs: {EPOCHS}\")"\n   ]\n  },\n  {\n   "cell_type": "markdown",\n   "metadata": {},\n   "source": [\n    "## 1. Load Preprocessed Data"\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "# Load data\n",\n    "X_train = np.load(os.path.join(PROCESSED_DATA_DIR, 'X_train.npy'))\n",\n    "y_train = np.load(os.path.join(PROCESSED_DATA_DIR, 'y_train.npy'))\n",\n    "X_val = np.load(os.path.join(PROCESSED_DATA_DIR, 'X_val.npy'))\n",\n    "y_val = np.load(os.path.join(PROCESSED_DATA_DIR, 'y_val.npy'))\n",\n    "X_test = np.load(os.path.join(PROCESSED_DATA_DIR, 'X_test.npy'))\n",\n    "y_test = np.load(os.path.join(PROCESSED_DATA_DIR, 'y_test.npy'))\n",\n    "\n",\n    "print(f\"Training set: {X_train.shape}\")\n",\n    "print(f\"Validation set: {X_val.shape}\")\n",\n    "print(f\"Test set: {X_test.shape}\")"\n   ]\n  },\n  {\n   "cell_type": "markdown",\n   "metadata": {},\n   "source": [\n    "## 2. Data Augmentation"\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "# Data augmentation for training\n",\n    "data_augmentation = keras.Sequential([\n",\n    "    layers.RandomFlip(\"horizontal\"),\n",\n    "    layers.RandomRotation(0.1),\n",\n    "    layers.RandomZoom(0.1),\n",\n    "    layers.RandomBrightness(0.1),\n",\n    "]\n",\n    "\n",\n    "# Visualize augmentation\n",\n    "sample_image = X_train[0:1]\n",\n    "fig, axes = plt.subplots(1, 4, figsize=(12, 3))\n",\n    "axes[0].imshow(sample_image[0])\n",\n    "axes[0].set_title('Original')\n",\n    "axes[0].axis('off')\n",\n    "\n",\n    "for i in range(1, 4):\n",\n    "    augmented = data_augmentation(sample_image, training=True)\n",\n    "    axes[i].imshow(augmented[0])\n",\n    "    axes[i].set_title(f'Augmented {i}')\n",\n    "    axes[i].axis('off')\n",\n    "\n",\n    "plt.suptitle('Data Augmentation Examples')\n",\n    "plt.tight_layout()\n",\n    "plt.show()"\n   ]\n  },\n  {\n   "cell_type": "markdown",\n   "metadata": {},\n   "source": [\n    "## 3. Build Ultra-Lightweight MobileNetV2 Model"\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "def build_model(input_shape=INPUT_SHAPE, alpha=ALPHA):\n",\n    "    \"\"\"Build ultra-lightweight MobileNetV2 model\"\"\"\n",\n    "    \n",\n    "    # Input layer\n",\n    "    inputs = keras.Input(shape=input_shape)\n",\n    "    \n",\n    "    # Data augmentation (only applied during training)\n",\n    "    x = data_augmentation(inputs)\n",\n    "    \n",\n    "    # MobileNetV2 base (no pre-trained weights for custom thermal images)\n",\n    "    base_model = MobileNetV2(\n",\n    "        input_shape=input_shape,\n",\n    "        alpha=alpha,\n",\n    "        include_top=False,\n",\n    "        weights=None,  # Train from scratch for thermal imaging\n",\n    "        pooling='avg'\n",\n    "    )\n",\n    "    \n",\n    "    x = base_model(x, training=True)\n",\n    "    \n",\n    "    # Classification head\n",\n    "    x = layers.Dropout(0.2)(x)\n",\n    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",\n    "    \n",\n    "    model = keras.Model(inputs, outputs)\n",\n    "    \n",\n    "    return model\n",\n    "\n",\n    "# Build model\n",\n    "model = build_model()\n",\n    "model.summary()\n",\n    "\n",\n    "# Count parameters\n",\n    "total_params = model.count_params()\n",\n    "print(f\"\\n{'='*50}\")\n",\n    "print(f\"Total parameters: {total_params:,}\")\n",\n    "print(f\"Estimated model size: ~{total_params * 4 / 1024:.2f} KB (FP32)\")\n",\n    "print(f\"Estimated model size after INT8 quantization: ~{total_params / 1024:.2f} KB\")\n",\n    "print(f\"{'='*50}\")"\n   ]\n  },\n  {\n   "cell_type": "markdown",\n   "metadata": {},\n   "source": [\n    "## 4. Compile Model"\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "# Compile model\n",\n    "model.compile(\n",\n    "    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",\n    "    loss='binary_crossentropy',\n",\n    "    metrics=[\n",\n    "        'accuracy',\n",\n    "        keras.metrics.Precision(name='precision'),\n",\n    "        keras.metrics.Recall(name='recall'),\n",\n    "        keras.metrics.AUC(name='auc')\n",\n    "    ]\n",\n    ")\n",\n    "\n",\n    "print(\"Model compiled successfully!\")"\n   ]\n  },\n  {\n   "cell_type": "markdown",\n   "metadata": {},\n   "source": [\n    "## 5. Setup Callbacks"\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "# Callbacks\n",\n    "callbacks = [\n",\n    "    EarlyStopping(\n",\n    "        monitor='val_loss',\n",\n    "        patience=15,\n",\n    "        restore_best_weights=True,\n",\n    "        verbose=1\n",\n    "    ),\n",\n    "    ModelCheckpoint(\n",\n    "        os.path.join(MODEL_DIR, 'mobilenetv2_best.h5'),\n",\n    "        monitor='val_accuracy',\n",\n    "        save_best_only=True,\n",\n    "        verbose=1\n",\n    "    ),\n",\n    "    ReduceLROnPlateau(\n",\n    "        monitor='val_loss',\n",\n    "        factor=0.5,\n",\n    "        patience=5,\n",\n    "        min_lr=1e-7,\n",\n    "        verbose=1\n",\n    "    )\n",\n    "]\n",\n    "\n",\n    "print(\"Callbacks configured.\")"\n   ]\n  },\n  {\n   "cell_type": "markdown",\n   "metadata": {},\n   "source": [\n    "## 6. Train Model"\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "# Train model\n",\n    "history = model.fit(\n",\n    "    X_train, y_train,\n",\n    "    validation_data=(X_val, y_val),\n",\n    "    batch_size=BATCH_SIZE,\n",\n    "    epochs=EPOCHS,\n",\n    "    callbacks=callbacks,\n",\n    "    verbose=1\n",\n    ")\n",\n    "\n",\n    "print(\"\\n✅ Training completed!\")"\n   ]\n  },\n  {\n   "cell_type": "markdown",\n   "metadata": {},\n   "source": [\n    "## 7. Plot Training History"\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "def plot_training_history(history):\n",\n    "    \"\"\"Plot training metrics\"\"\"\n",\n    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",\n    "    \n",\n    "    # Accuracy\n",\n    "    axes[0, 0].plot(history.history['accuracy'], label='Train')\n",\n    "    axes[0, 0].plot(history.history['val_accuracy'], label='Validation')\n",\n    "    axes[0, 0].set_title('Model Accuracy')\n",\n    "    axes[0, 0].set_xlabel('Epoch')\n",\n    "    axes[0, 0].set_ylabel('Accuracy')\n",\n    "    axes[0, 0].legend()\n",\n    "    axes[0, 0].grid(True)\n",\n    "    \n",\n    "    # Loss\n",\n    "    axes[0, 1].plot(history.history['loss'], label='Train')\n",\n    "    axes[0, 1].plot(history.history['val_loss'], label='Validation')\n",\n    "    axes[0, 1].set_title('Model Loss')\n",\n    "    axes[0, 1].set_xlabel('Epoch')\n",\n    "    axes[0, 1].set_ylabel('Loss')\n",\n    "    axes[0, 1].legend()\n",\n    "    axes[0, 1].grid(True)\n",\n    "    \n",\n    "    # Precision\n",\n    "    axes[1, 0].plot(history.history['precision'], label='Train')\n",\n    "    axes[1, 0].plot(history.history['val_precision'], label='Validation')\n",\n    "    axes[1, 0].set_title('Model Precision')\n",\n    "    axes[1, 0].set_xlabel('Epoch')\n",\n    "    axes[1, 0].set_ylabel('Precision')\n",\n    "    axes[1, 0].legend()\n",\n    "    axes[1, 0].grid(True)\n",\n    "    \n",\n    "    # Recall\n",\n    "    axes[1, 1].plot(history.history['recall'], label='Train')\n",\n    "    axes[1, 1].plot(history.history['val_recall'], label='Validation')\n",\n    "    axes[1, 1].set_title('Model Recall')\n",\n    "    axes[1, 1].set_xlabel('Epoch')\n",\n    "    axes[1, 1].set_ylabel('Recall')\n",\n    "    axes[1, 1].legend()\n",\n    "    axes[1, 1].grid(True)\n",\n    "    \n",\n    "    plt.tight_layout()\n",\n    "    plt.savefig(os.path.join(MODEL_DIR, 'training_history.png'), dpi=300)\n",\n    "    plt.show()\n",\n    "\n",\n    "plot_training_history(history)"\n   ]\n  },\n  {\n   "cell_type": "markdown",\n   "metadata": {},\n   "source": [\n    "## 8. Evaluate on Test Set"\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "# Evaluate on test set\n",\n    "test_loss, test_acc, test_precision, test_recall, test_auc = model.evaluate(X_test, y_test, verbose=0)\n",\n    "\n",\n    "print(\"\\n\" + \"="*50)\n",\n    "print(\"TEST SET RESULTS\")\n",\n    "print(\"="*50)\n",\n    "print(f\"Loss: {test_loss:.4f}\")\n",\n    "print(f\"Accuracy: {test_acc:.4f}\")\n",\n    "print(f\"Precision: {test_precision:.4f}\")\n",\n    "print(f\"Recall: {test_recall:.4f}\")\n",\n    "print(f\"AUC: {test_auc:.4f}\")\n",\n    "print(\"="*50)\n",\n    "\n",\n    "# Predictions\n",\n    "y_pred_proba = model.predict(X_test)\n",\n    "y_pred = (y_pred_proba > 0.5).astype(int).flatten()\n",\n    "\n",\n    "# Classification report\n",\n    "print(\"\\nClassification Report:\")\n",\n    "print(classification_report(y_test, y_pred, target_names=['Healthy', 'Cancer']))"\n   ]\n  },\n  {\n   "cell_type": "markdown",\n   "metadata": {},\n   "source": [\n    "## 9. Confusion Matrix"\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "# Confusion matrix\n",\n    "cm = confusion_matrix(y_test, y_pred)\n",\n    "\n",\n    "plt.figure(figsize=(8, 6))\n",\n    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",\n    "            xticklabels=['Healthy', 'Cancer'],\n",\n    "            yticklabels=['Healthy', 'Cancer'])\n",\n    "plt.title('Confusion Matrix')\n",\n    "plt.ylabel('True Label')\n",\n    "plt.xlabel('Predicted Label')\n",\n    "plt.savefig(os.path.join(MODEL_DIR, 'confusion_matrix.png'), dpi=300)\n",\n    "plt.show()"\n   ]\n  },\n  {\n   "cell_type": "markdown",\n   "metadata": {},\n   "source": [\n    "## 10. ROC Curve"\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "# ROC curve\n",\n    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",\n    "roc_auc = auc(fpr, tpr)\n",\n    "\n",\n    "plt.figure(figsize=(8, 6))\n",\n    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",\n    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",\n    "plt.xlim([0.0, 1.0])\n",\n    "plt.ylim([0.0, 1.05])\n",\n    "plt.xlabel('False Positive Rate')\n",\n    "plt.ylabel('True Positive Rate')\n",\n    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",\n    "plt.legend(loc=\"lower right\")\n",\n    "plt.grid(True)\n",\n    "plt.savefig(os.path.join(MODEL_DIR, 'roc_curve.png'), dpi=300)\n",\n    "plt.show()"\n   ]\n  },\n  {\n   "cell_type": "markdown",\n   "metadata": {},\n   "source": [\n    "## 11. Save Base Model"\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "# Save the final model\n",\n    "model.save(os.path.join(MODEL_DIR, 'mobilenetv2_base.h5'))\n",\n    "print(f\"✅ Base model saved to {os.path.join(MODEL_DIR, 'mobilenetv2_base.h5')}\")"\n   ]\n  },\n  {\n   "cell_type": "markdown",\n   "metadata": {},\n   "source": [\n    "## 12. Post-Training Quantization (PTQ)"\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "def representative_dataset():\n",\n    "    \"\"\"Representative dataset for quantization calibration\"\"\"\n",\n    "    for i in range(min(100, len(X_train))):\n",\n    "        yield [X_train[i:i+1].astype(np.float32)]\n",\n    "\n",\n    "# Convert to TFLite with quantization\n",\n    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",\n    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",\n    "converter.representative_dataset = representative_dataset\n",\n    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",\n    "converter.inference_input_type = tf.int8\n",\n    "converter.inference_output_type = tf.int8\n",\n    "\n",\n    "tflite_quantized_model = converter.convert()\n",\n    "\n",\n    "# Save quantized model\n",\n    "tflite_model_path = os.path.join(MODEL_DIR, 'mobilenetv2_quantized.tflite')\n",\n    "with open(tflite_model_path, 'wb') as f:\n",\n    "    f.write(tflite_quantized_model)\n",\n    "\n",\n    "print(f\"\\n✅ Quantized model saved to {tflite_model_path}\")\n",\n    "print(f\"Model size: {len(tflite_quantized_model) / 1024:.2f} KB\")"\n   ]\n  },\n  {\n   "cell_type": "markdown",\n   "metadata": {},\n   "source": [\n    "## 13. Evaluate Quantized Model"\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "def evaluate_tflite_model(tflite_model, X_test, y_test):\n",\n    "    \"\"\"Evaluate TFLite model\"\"\"\n",\n    "    interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",\n    "    interpreter.allocate_tensors()\n",\n    "    \n",\n    "    input_details = interpreter.get_input_details()\n",\n    "    output_details = interpreter.get_output_details()\n",\n    "    \n",\n    "    input_scale, input_zero_point = input_details[0]['quantization']\n",\n    "    output_scale, output_zero_point = output_details[0]['quantization']\n",\n    "    \n",\n    "    predictions = []\n",\n    "    \n",\n    "    for i in range(len(X_test)):\n",\n    "        # Quantize input\n",\n    "        input_data = X_test[i:i+1].astype(np.float32)\n",\n    "        input_data = input_data / input_scale + input_zero_point\n",\n    "        input_data = input_data.astype(np.int8)\n",\n    "        \n",\n    "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",\n    "        interpreter.invoke()\n",\n    "        \n",\n    "        # Dequantize output\n",\n    "        output_data = interpreter.get_tensor(output_details[0]['index'])\n",\n    "        output_data = (output_data.astype(np.float32) - output_zero_point) * output_scale\n",\n    "        \n",\n    "        predictions.append(output_data[0][0])\n",\n    "    \n",\n    "    predictions = np.array(predictions)\n",\n    "    y_pred = (predictions > 0.5).astype(int)\n",\n    "    \n",\n    "    accuracy = np.mean(y_pred == y_test)\n",\n    "    \n",\n    "    return accuracy, predictions\n",\n    "\n",\n    "# Evaluate quantized model\n",\n    "quant_accuracy, quant_predictions = evaluate_tflite_model(tflite_quantized_model, X_test, y_test)\n",\n    "\n",\n    "print(\"\\n\" + \"="*50)\n",\n    "print(\"QUANTIZED MODEL RESULTS\")\n",\n    "print(\"="*50)\n",\n    "print(f\"Original Model Accuracy: {test_acc:.4f}\")\n",\n    "print(f\"Quantized Model Accuracy: {quant_accuracy:.4f}\")\n",\n    "print(f\"Accuracy Drop: {(test_acc - quant_accuracy):.4f}\")\n",\n    "print(\"="*50)\n"\n   ]\n  },\n  {\n   "cell_type": "markdown",\n   "metadata": {},\n   "source": [\n    "## 14. Model Summary"\n   ]\n  },\n  {\n   "cell_type": "code",\n   "execution_count": null,\n   "metadata": {},\n   "outputs": [],\n   "source": [\n    "# Get model sizes\n",\n    "base_model_size = os.path.getsize(os.path.join(MODEL_DIR, 'mobilenetv2_base.h5')) / 1024\n",\n    "quantized_model_size = len(tflite_quantized_model) / 1024\n",\n    "\n",\n    "print(\"\\n\" + \"="*50)\n",\n    "print(\"MODEL SUMMARY\")\n",\n    "print(\"="*50)\n",\n    "print(f\"Architecture: MobileNetV2 (α={ALPHA})\")\n",\n    "print(f\"Input Size: {IMAGE_SIZE}×{IMAGE_SIZE}×3\")\n",\n    "print(f\"Total Parameters: {total_params:,}\")\n",\n    "print(f\"\nModel Sizes:\")\n",\n    "print(f\"  - Base Model (FP32): {base_model_size:.2f} KB\")\n",\n    "print(f\"  - Quantized Model (INT8): {quantized_model_size:.2f} KB\")\n",\n    "print(f\"  - Compression Ratio: {base_model_size/quantized_model_size:.2f}x\")\n",\n    "print(f\"\nPerformance:\")\n",\n    "print(f\"  - Test Accuracy (FP32): {test_acc:.4f}\")\n",\n    "print(f\"  - Test Accuracy (INT8): {quant_accuracy:.4f}\")\n",\n    "print(f\"  - AUC: {test_auc:.4f}\")\n",\n    "print(\"="*50)\n",\n    "print(\"\n✅ Ready for MAX78000 deployment!\")\n",\n    "print(\"Next: Run notebook 03_model_export.ipynb\")"\n   ]\n  }\n ],\n "metadata": {\n  "kernelspec": {\n   "display_name": "Python 3",\n   "language": "python",\n   "name": "python3"\n  },\n  "language_info": {\n   "codemirror_mode": {\n    "name": "ipython",\n    "version": 3\n   },\n   "file_extension": ".py",\n   "mimetype": "text/x-python",\n   "name": "python",\n   "nbconvert_exporter": "python",\n   "pygments_lexer": "ipython3",\n   "version": "3.8.0"\n  }\n },\n "nbformat": 4,\n "nbformat_minor": 4\n}